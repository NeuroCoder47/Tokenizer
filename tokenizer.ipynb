{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ashmi\\Documents\\Artificial Intelligence\\.venv\\Lib\\site-packages\\torchtext\\datasets\\__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "c:\\Users\\ashmi\\Documents\\Artificial Intelligence\\.venv\\Lib\\site-packages\\torchtext\\data\\__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "c:\\Users\\ashmi\\Documents\\Artificial Intelligence\\.venv\\Lib\\site-packages\\torchtext\\vocab\\__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "c:\\Users\\ashmi\\Documents\\Artificial Intelligence\\.venv\\Lib\\site-packages\\torchtext\\utils.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "c:\\Users\\ashmi\\Documents\\Artificial Intelligence\\.venv\\Lib\\site-packages\\torchtext\\transforms.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "c:\\Users\\ashmi\\Documents\\Artificial Intelligence\\.venv\\Lib\\site-packages\\torchtext\\functional.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import io\n",
    "import re\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "from torchtext.datasets import WikiText2, EnWik9, AG_NEWS\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "import torchtext.transforms as T\n",
    "from torch.hub import load_state_dict_from_url\n",
    "from torchtext.data.functional import sentencepiece_tokenizer, load_sp_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"HuggingFaceTB/cosmopedia-100k\", cache_dir=r\"C:\\Users\\Downloads\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt': 'Here is an extract from a webpage: \"What can cause my settlement offer to be delayed?\\nWhen you’ve been injured in an Austin truck accident, one of the most common questions is how long it will take for the insurance company to make an offer to settle your case. The answer depends on a variety of factors.\\nThe process starts with filing an insurance claim and providing evidence that shows exactly what happened during the accident and who was at fault. This can involve gathering key Austin truck accident evidence such as:\\n- Medical records\\n- Photographs or video footage of the crash scene\\n- Witness statements\\n- Other documents related to your injuries and damages.\\nOnce this information has been collected by both sides, negotiations may begin between your Austin truck accident lawyer and the insurance company on how much compensation should be offered in exchange for settling the case out of court.\\nIt is important to remember that every truck accident case is unique so there is no set timeline as far as when a settlement mig\".\\n\\nWrite an informative and insightful blog post that expands upon the extract above. Your post should delve into the nuances of the topic, offering fresh perspectives and deeper analysis. Aim to:\\n\\n- Inform: Provide valuable, well-researched information that educates the reader.\\n- Engage: Write in a conversational tone that connects with the audience, making complex ideas accessible.\\n- Illustrate: Use examples, anecdotes, or personal experiences to bring the topic to life.\\nDo not give a title and do not start with sentences like \"Have you ever...\" or \"Hello dear readers..\", simply write the content without these introductory phrases.', 'text_token_length': 585, 'text': \" When you've been involved in an auto accident, particularly one involving a commercial truck, receiving a settlement offer from the insurance company is often top of mind. After all, medical bills, lost wages, and property damage can quickly add up, leaving you financially strained. However, the timing of a settlement offer can vary greatly depending on several factors. Let's delve deeper into the nuances of this topic.\\n\\nFirst and foremost, before any settlement negotiation can occur, it's crucial to establish liability. Gathering evidence such as medical records, photographs, witness statements, and other relevant documentation helps build a solid foundation for your case. An experienced Austin truck accident attorney can guide you through this process and ensure that all necessary evidence is gathered and presented effectively. \\n\\nOne factor that can significantly impact the timeline of a settlement offer is the complexity of the case itself. For instance, if multiple parties are involved, determining responsibility becomes more intricate, potentially delaying the settlement process. Additionally, cases involving severe injuries usually require extensive medical evaluations and treatment plans, which takes time to compile and present accurately.\\n\\nAnother critical aspect influencing the speed of a settlement offer is communication between the two negotiating parties – i.e., your legal representative and the insurance adjuster. While some adjusters work diligently to resolve claims swiftly, others might employ stall tactics designed to lowball offers or wear down claimants. Patience and perseverance are essential here; attempting to rush the process could result in a lower payout than what you rightfully deserve.\\n\\nFurthermore, keep in mind that each case is unique, meaning there's no standard timeline for receiving a settlement offer following a truck accident. Some claims may reach resolution within months, while others might drag on for over a year due to unforeseen complications or disputes. It's vital to stay informed throughout the process, maintaining open lines of communication with your attorney to understand where things stand and what to expect moving forward.\\n\\nLastly, consider mediation as a viable option if negotiations become tense or protracted. Mediators act as impartial third parties who facilitate discussions between opposing counsel, aiming to find middle ground and expedite resolutions. By bringing in a mediator, both sides agree to compromise, often leading to faster (and fairer) outcomes.\\n\\nIn conclusion, various elements contribute to the length of time it takes for a settlement offer after an Austin truck accident. Building a strong case through thorough evidence collection, exercising patience during negotiations, and considering alternative dispute resolution methods can help streamline the process. Remember, staying informed and working closely with an experienced truck accident lawyer increases your chances of securing a favorable outcome, even if it requires a bit of waiting.\", 'seed_data': 'web_samples_v2', 'format': 'blogpost', 'audience': 'general'}\n",
      "Dataset successfully saved to CSV.\n"
     ]
    }
   ],
   "source": [
    "print(ds['train'][0])\n",
    "\n",
    "# Convert the dataset to a Pandas DataFrame\n",
    "df = pd.DataFrame(ds['train'])\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(r\"C:\\Users\\cosmopedia_100k_train.csv\", index=False)\n",
    "\n",
    "print(\"Dataset successfully saved to CSV.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully split and saved to train_data.csv and test_data.csv.\n",
      "Files successfully combined into combined_data.csv.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv(r\"C:\\Users\\cosmopedia_100k_train.csv\")\n",
    "\n",
    "\n",
    "df = df.drop(columns=['seed_data', 'format', 'audience', 'text_token_length', 'prompt'])\n",
    "\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "def clean_text(df):\n",
    "    df['text'] = df['text'].apply(lambda text: re.sub(r'\\|\\n|;', ' ', text.replace('\"', ' ').replace('\\n', ' ')).lower())\n",
    "    return df\n",
    "\n",
    "\n",
    "train_df = clean_text(train_df)\n",
    "test_df = clean_text(test_df)\n",
    "\n",
    "data_set_root = r\"C:\\Users\\Downloads\"\n",
    "train_csv_path = os.path.join(data_set_root, \"train_data.csv\")\n",
    "test_csv_path = os.path.join(data_set_root, \"test_data.csv\")\n",
    "\n",
    "train_df.to_csv(train_csv_path, index=False, encoding=\"utf-8\")\n",
    "test_df.to_csv(test_csv_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"Data successfully split and saved to train_data.csv and test_data.csv.\")\n",
    "\n",
    "\n",
    "combined_csv_path = os.path.join(data_set_root, \"combined_data.csv\")\n",
    "combined_df = pd.concat([train_df, test_df], ignore_index=True)\n",
    "combined_df.to_csv(combined_csv_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"Files successfully combined into combined_data.csv.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoader objects created successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.texts = df['text'].tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts[idx]\n",
    "dataset_train = TextDataset(train_df)\n",
    "dataset_test = TextDataset(test_df)\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "shuffle = True\n",
    "\n",
    "\n",
    "data_loader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=shuffle)\n",
    "data_loader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(\"DataLoader objects created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sentencepiece as spm\n",
    "\n",
    "options = dict(\n",
    "\n",
    "  input=r\"C:\\Users\\ashmi\\Downloads\\combined_data.txt\", \n",
    "  input_format=\"text\",\n",
    "\n",
    "  model_prefix=\"tok400\",  \n",
    " \n",
    "  model_type=\"bpe\",\n",
    "  vocab_size=384613, \n",
    "\n",
    "  normalization_rule_name=\"identity\", \n",
    "  remove_extra_whitespaces=False,\n",
    "  input_sentence_size=100059,  \n",
    "  max_sentence_length=4192,  \n",
    "  seed_sentencepiece_size=1000000,\n",
    "  shuffle_input_sentence=True,\n",
    "\n",
    "  character_coverage=0.99995,\n",
    "  byte_fallback=True,\n",
    "  \n",
    "  split_digits=True,\n",
    "  split_by_unicode_script=True,\n",
    "  split_by_whitespace=True,\n",
    "  split_by_number=True,\n",
    "  max_sentencepiece_length=16,\n",
    "  add_dummy_prefix=True,\n",
    "  allow_whitespace_only_pieces=True,\n",
    " \n",
    "  unk_id=0,  \n",
    "  bos_id=1,  \n",
    "  eos_id=2,\n",
    "  pad_id=-1,\n",
    "\n",
    "  num_threads=os.cpu_count(), \n",
    ")\n",
    "\n",
    "\n",
    "spm.SentencePieceTrainer.train(**options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sentence: hi how are you\n",
      "Tokenized Sentence: ['▁hi', '▁how', '▁are', '▁you']\n",
      "Token IDs: [5305, 472, 527, 352]\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "\n",
    "model_path = \"tok400.model\" \n",
    "sp = spm.SentencePieceProcessor(model_file=r\"C:\\Users\\ashmi\\tok400.model\")\n",
    "\n",
    "def tokenize_and_convert(sentence):\n",
    "    \n",
    "    tokens = sp.encode(sentence, out_type=str)  \n",
    "    \n",
    "\n",
    "    token_ids = sp.encode(sentence, out_type=int) \n",
    "    \n",
    "    return tokens, token_ids\n",
    "\n",
    "\n",
    "sentence = \"hi how are you\"\n",
    "\n",
    "tokens, token_ids = tokenize_and_convert(sentence)\n",
    "\n",
    "\n",
    "print(\"Original Sentence:\", sentence)\n",
    "print(\"Tokenized Sentence:\", tokens)\n",
    "print(\"Token IDs:\", token_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "795022"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100059"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_count \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
